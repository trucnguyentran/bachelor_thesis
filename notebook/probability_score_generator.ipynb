{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truc Tran -- i6213546\n",
    "### Topics available\n",
    "  ## Update \"/dbfs/sh-recommender-pred-data/introduction_blocks_topics.csv\" file when new topic is introduced\n",
    "### Input for Data class:\n",
    "  ## user features, block features, block started, block finished, question played, video played tables\n",
    "### Input for Predictor class:\n",
    "  ## training data and predicting data got from Data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "13125601-18dd-46cb-8423-0b42732ede71",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from habtic_data_ml_pipeline.utils.feature_generator_framework import FeaturesTableGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fa1b3979-bfa1-4c85-9936-b9d1eb6102d6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data class: Get training and predicting data for probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e4f673f-7f19-47ed-8dc9-d72d459fdf50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Extract all features for training model\n",
    "  Args:\n",
    "    tables: user features, block features, block_started, block_finished, question_played, video_played events\n",
    "    return: \n",
    "      - Training features table (exclude the latest state)\n",
    "      - Predicting features table\n",
    "\"\"\"\n",
    "class Data:\n",
    "  def __init__(self, user_ft, block_ft, block_start, block_finish, question, video):\n",
    "    self.user_ft = user_ft\n",
    "    self.block_ft = block_ft\n",
    "    self.block_start = block_start\n",
    "    self.block_finish = block_finish\n",
    "    self.question = question\n",
    "    self.video = video\n",
    "    \"\"\"\n",
    "      add new introduction block here when new topic is introduced\n",
    "    \"\"\"\n",
    "    self.introduction_blocks = ['pa2-module1', 'better-breathing', 'bhh1-module1', 'moving-during-long-distance-travel', 'ilt2-module1',\\\n",
    "                                'iyp1-module1', 'my-private-moment', 'optimizing-memory', 'os1-module1', 'conversation-tensing-to-relax', 'sleep-and-shift-work-p1', 'clc1-module1',\\\n",
    "                                'conversation-dealing-with-conflicts', 'exploring-creativity', 'regulating-emotions', 'kyb2-module1', 'conversation-working-behind-a-monitor',\\\n",
    "                                'ub2-module1', 'sp2-module1', 'wr1-module1', 'hhw1-module1', 'managing-sources-of-chronic-stress', 'ensuring-future-vitality', 'isc1-module1']\n",
    "    self.session_features()\n",
    "    self.block_cluster()\n",
    "    self.user_block_last_info()\n",
    "    \n",
    "  def session_features(self):\n",
    "    \"\"\"\n",
    "    Extract numerical features for each session\n",
    "    Args:\n",
    "        df_block_started (pd.DataFrame): A dataframe of block started event.\n",
    "        df_block_finished (pd.DataFrame): A dataframe of block finished event.\n",
    "    Returns:\n",
    "        pd.Dataframe: features for ech session\n",
    "    Raises: None\n",
    "    \"\"\"\n",
    "    start = self.block_start.groupby([\"UserId\", \"BlockCode\", \"AppSessionId\"]).agg({\"TimestampUtc\":\"min\", \"EventId\":\"max\"}).reset_index()\n",
    "    start.columns = [\"UserId\", \"BlockCode\", \"AppSessionId\", \"time_start\", \"id_start\"]\n",
    "    finish = self.block_finish.groupby([\"UserId\", \"BlockCode\", \"AppSessionId\"]).agg({\"TimestampUtc\":\"max\", \"CompletionState\":\"max\"}).reset_index()\n",
    "    finish.columns =[\"UserId\", \"BlockCode\", \"AppSessionId\", \"time_finish\", \"CompletionState\"]\n",
    "    self.session = start.merge(finish, on=[\"UserId\", \"BlockCode\", \"AppSessionId\"],how=\"inner\")\n",
    "    self.session[\"duration\"] = self.session.apply(lambda x: (x[\"time_finish\"] - x[\"time_start\"]).seconds, axis=1)\n",
    "    self.session.reset_index(drop=True)\n",
    "    return self.session;\n",
    "  \n",
    "  def block_cluster(self, clique_size=10, epsilon_dist=1.e-5):\n",
    "    \"\"\"\n",
    "    Makes cliques of blocks -- for each block, find the closest clique_size blocks\n",
    "    Args:\n",
    "        df_block_features (pd.DataFrame): A dataframe of block features.\n",
    "        clique_size (int, optional): The size of clique to calculate for each block\n",
    "        epsilon_dist(float, optional): A small positive number to to each distance so that distance is always positive\n",
    "    Returns:\n",
    "        pd.Dataframe: Cliques and distances for each block\n",
    "    Raises: None\n",
    "    \"\"\"\n",
    "    features = self.block_ft.select_dtypes(\"number\")\n",
    "    scaled_features = StandardScaler().fit_transform(features)\n",
    "    distances = nan_euclidean_distances(scaled_features, scaled_features)\n",
    "    clique_indexes = np.argpartition(distances, clique_size+1)\n",
    "    self.block_clique = pd.DataFrame(columns=[\"BlockCode\", \"clique_blocks\", \"clique_distances\"])\n",
    "    for i in range(len(self.block_ft)):\n",
    "      block_id = self.block_ft[\"BlockCode\"][i]\n",
    "      clique_block_id_list = []\n",
    "      clique_block_dist_list = []\n",
    "      for j in range(clique_size+1):\n",
    "        if clique_indexes[i][j] == i: continue;\n",
    "        c_id = self.block_ft[\"BlockCode\"][clique_indexes[i][j]]\n",
    "        clique_block_id_list.append(c_id)\n",
    "        c_dist = distances[i][clique_indexes[i][j]] + epsilon_dist\n",
    "        clique_block_dist_list.append(c_dist)\n",
    "      self.block_clique.loc[len(self.block_clique)] = [block_id, clique_block_id_list, clique_block_dist_list]\n",
    "    return self.block_clique;\n",
    "  \n",
    "  # lastest state of each (user-block)\n",
    "  def user_block_last_info(self):\n",
    "    self.latest_info = self.session.groupby([\"UserId\", \"BlockCode\"])[\"time_finish\"].max().reset_index(name=\"time_finish\")\n",
    "    self.latest_info = self.latest_info.merge(self.session, on=[\"UserId\", \"BlockCode\", \"time_finish\"], how=\"inner\")\n",
    "    self.latest_info = self.latest_info[[\"UserId\", \"BlockCode\", \"id_start\", \"time_finish\", \"CompletionState\"]].reset_index(drop=True)\n",
    "    return self.latest_info\n",
    "  \n",
    "  # take out the latest state of each pair (user-block) to train the model\n",
    "  def remove_latest_info(self):\n",
    "    df_latest = self.latest_info.copy()\n",
    "    df_latest[\"user_block\"] = df_latest[\"UserId\"] + \" \" + df_latest[\"BlockCode\"]\n",
    "    df_all = self.session.groupby([\"UserId\", \"BlockCode\"])[\"CompletionState\"].count().reset_index(name=\"total_times_played\")\n",
    "    df_all[\"user_block\"] = df_all[\"UserId\"] + \" \" + df_all[\"BlockCode\"]\n",
    "    one_time_list = df_all[df_all[\"total_times_played\"]==1][\"user_block\"]\n",
    "    df_latest = df_latest[~df_latest[\"user_block\"].isin(one_time_list)].reset_index(drop=True)\n",
    "    for i in range(len(df_latest)):\n",
    "      id_start = df_latest.iloc[i][\"id_start\"]\n",
    "      ret_df = self.session.drop(self.session.index[(self.session[\"id_start\"] == id_start)])\n",
    "    return ret_df;\n",
    "  \n",
    "  # take out every possible (user-block) pair for score estimation\n",
    "  def combine_not_trigger_block(self, df_user_block):\n",
    "    users, blocks = self.user_ft[\"UserId\"].unique(), self.block_ft[\"BlockCode\"].unique()\n",
    "    new_users, new_blocks = [], []\n",
    "    user_block = [i+\" \"+j for j in blocks for i in users]\n",
    "    user_block = [i for i in user_block if i not in list(df_user_block[\"user_and_block\"])]\n",
    "    if len(user_block)==0:\n",
    "      return df_user_block\n",
    "    else:\n",
    "      for i in user_block:\n",
    "        new_users.append(i.split(\" \")[0])\n",
    "        new_blocks.append(i.split(\" \")[1])\n",
    "      df = pd.DataFrame(columns = df_user_block.columns)\n",
    "      for c in df.columns:\n",
    "        if (c==\"UserId\"): df[c] = new_users\n",
    "        elif (c==\"BlockCode\"): df[c] = new_blocks\n",
    "        elif (c==\"user_and_block\"): df[c] = user_block\n",
    "        else: df[c] = 0\n",
    "      frame = [df_user_block, df]\n",
    "      df = pd.concat(frame).reset_index(drop=True)\n",
    "    return df;\n",
    "  \n",
    "  # extract neighboring features for user-block\n",
    "  def total_avg_clique(self, x, features, df_user_block):\n",
    "    total, avg = [], []\n",
    "    for feature in features:\n",
    "      blocklist = np.append(x.clique_blocks, x.BlockCode)\n",
    "      filter = df_user_block[(df_user_block[\"UserId\"] == x.UserId) & (df_user_block[\"BlockCode\"].isin(blocklist))][[\"BlockCode\", feature]]\n",
    "      total_feature = filter[feature].sum()\n",
    "      total.append(total_feature)\n",
    "      \n",
    "      filter.reset_index(drop=True, inplace=True)\n",
    "      distances = np.append((np.array(x.clique_distances)/(np.array(x.clique_distances).min()*0.99)), 1)\n",
    "      avg_feature, count = 0, 0\n",
    "      for i in range(len(filter)):\n",
    "        block = filter[\"BlockCode\"].iloc[i]\n",
    "        index = list(blocklist).index(block)\n",
    "        temp = filter.loc[filter.BlockCode == block][feature].iloc[0]\n",
    "        if temp != 0:\n",
    "          avg_feature += temp/(distances[index]**2)\n",
    "          count += 1\n",
    "      if avg_feature != 0: avg_feature /= count\n",
    "      avg.append(avg_feature)\n",
    "    result = np.append(total, avg)\n",
    "    return result\n",
    "  \n",
    "  def clique_features(self, df_user_block, df):   \n",
    "    features = [\"block_played\", \"block_completed\", \"question_played\", \n",
    "              \"question_completed\", \"video_played\", \"video_completed\", \"total_time_spent\",\n",
    "               \"total_time_watched\", \"mean_time_watched\"]\n",
    "    results = list(df_user_block.apply(self.total_avg_clique, args=[features, df], axis = 1))\n",
    "    total_features = ['clique_'+i for i in features]\n",
    "    avg_features = ['clique_avg_'+i for i in features]\n",
    "    features = np.append(total_features, avg_features)\n",
    "    df_user_block[features] = results\n",
    "    return df_user_block\n",
    "\n",
    "  # additional features: user oriented and block oriented\n",
    "  def add_user_block_oriented_ft(self, df_user_block):\n",
    "    user, block = self.user_ft.copy(), self.block_ft.copy()\n",
    "    for c in user.columns:\n",
    "      if user[c].isna().sum() > len(user)/2: user.drop(columns=[c], inplace=True)\n",
    "    cols = [\"UserId\"] + [\"user_ft_\"+i for i in user.columns if i != \"UserId\"]\n",
    "    user.columns = cols\n",
    "    df_user_block = df_user_block.merge(user, on=\"UserId\", how=\"left\")\n",
    "    \n",
    "    block.drop(columns=[\"blocks_unfinished\"], inplace= True)\n",
    "    block.columns = [\"BlockCode\", \"block_ft_block_played\", \"block_ft_block_completed\", \"block_ft_block_played_mean\", \"block_ft_no_user_played\", \\\n",
    "          \"block_ft_no_user_played_rate\", \"block_ft_block_duration_mean\", \"block_ft_block_duration_std\", \"block_ft_no_block_before\"]\n",
    "    for c in block.columns:\n",
    "      if block[c].isna().sum() > len(block)/2: block.drop(columns=[c], inplace=True)\n",
    "    df_user_block = df_user_block.merge(block, on=\"BlockCode\", how=\"left\")\n",
    "    return df_user_block\n",
    "  \n",
    "  # parallel processing\n",
    "  def parallelize_dataframe(self, args, func, n_cores=5):\n",
    "    pool = multiprocessing.Pool(n_cores)\n",
    "    #df = pd.concat(pool.starmap(func, args))\n",
    "    res = pool.starmap_async(func, args)\n",
    "    df = pd.concat(res.get(None), ignore_index=True).reset_index(drop=True)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "  # extract all features\n",
    "  def extract_all_features(self, latest = True):\n",
    "    vid, ques, df_session = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "    if latest == False:\n",
    "      df_session = self.remove_latest_info()\n",
    "      vid = self.video[self.video[\"AppSessionId\"].isin(self.session.AppSessionId.unique())]\n",
    "      ques = self.question[self.question[\"AppSessionId\"].isin(self.session.AppSessionId.unique())]\n",
    "    else: \n",
    "      vid, ques, df_session = self.video, self.question, self.session\n",
    "    vid[\"Finished\"] = 1 - vid[\"Skipped\"]\n",
    "    vid[\"VideoLengthPlayed\"] = vid[\"VideoLengthPlayed\"].astype(float)\n",
    "    \n",
    "    v = vid.groupby([\"UserId\", \"BlockCode\"]).agg({\"Finished\":[\"count\",\"sum\"], \"VideoLengthPlayed\":[\"sum\", \"mean\"]}).reset_index()\n",
    "    v.columns = [\"UserId\", \"BlockCode\", \"video_played\", \"video_completed\", \"total_time_watched\", \"mean_time_watched\"]\n",
    "    q = ques.groupby([\"UserId\", \"BlockCode\"]).agg({\"CompletionState\":[\"count\",\"sum\"]}).reset_index()\n",
    "    q.columns = [\"UserId\", \"BlockCode\", \"question_played\", \"question_completed\"]\n",
    "    \n",
    "    user_block = df_session.groupby([\"UserId\", \"BlockCode\"]).agg({\"CompletionState\":[\"count\", \"sum\"], \"duration\":[\"sum\", \"mean\"]}).reset_index()\n",
    "    user_block.columns = [\"UserId\", \"BlockCode\", \"block_played\", \"block_completed\", \"total_time_spent\", \"avg_time_spent\",]\n",
    "    \n",
    "    user_block = user_block.merge(v, on = [\"UserId\", \"BlockCode\"], how = \"left\")\n",
    "    user_block = user_block.merge(q, on = [\"UserId\", \"BlockCode\"], how = \"left\")\n",
    "    user_block[\"block_completed_rate\"] = user_block[\"block_completed\"]/user_block[\"block_played\"]\n",
    "    user_block[\"question_completed_rate\"] = user_block[\"question_completed\"]/user_block[\"question_played\"]\n",
    "    user_block[\"video_completed_rate\"] = user_block[\"video_completed\"]/user_block[\"video_played\"]\n",
    "    user_block[\"user_and_block\"] = user_block[\"UserId\"] +\" \"+user_block[\"BlockCode\"]\n",
    "    \n",
    "    if latest == True:\n",
    "      user_block = self.combine_not_trigger_block(user_block)\n",
    "    user_block = self.add_user_block_oriented_ft(user_block)\n",
    "    user_block = user_block.merge(self.block_clique, on=\"BlockCode\",how=\"left\")\n",
    "    \n",
    "    user_block_ = user_block.copy()\n",
    "    if latest == True:\n",
    "      user_block = user_block[user_block.BlockCode.isin(self.introduction_blocks)].reset_index(drop=True)\n",
    "      \n",
    "    args = [(i, user_block_) for i in np.array_split(user_block, 1000)]\n",
    "    user_block = self.parallelize_dataframe(args = args, func=self.clique_features)\n",
    "\n",
    "    if latest == False:\n",
    "      df_latest = self.latest_info[[\"UserId\", \"BlockCode\", \"CompletionState\"]]\n",
    "      user_block = user_block.merge(df_latest, on=[\"UserId\", \"BlockCode\"], how=\"inner\")\n",
    "      user_block = user_block.rename(columns={\"CompletionState\":\"next_attempt\"})\n",
    "      user_block.to_csv(\"/dbfs/Truc/train.csv\")\n",
    "    else:\n",
    "      user_block.to_csv(\"/dbfs/Truc/predict.csv\")\n",
    "    return user_block\n",
    "    #else:\n",
    "      #return user_block\n",
    "  \n",
    "  def run(self):\n",
    "    self.training_data = self.extract_all_features(latest = False)\n",
    "    self.predicting_data = self.extract_all_features(latest = True)\n",
    "    return self.training_data, self.predicting_data\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8203be35-cd30-4c3b-9cef-bc85b099ed37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Predictor: All methods to train and estimate probability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9822d345-99a5-450a-8352-b719c05035d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "  def __init__(self, train_data, predict_data):\n",
    "    self.train_data = train_data\n",
    "    self.predict_data = self.normalize_data(data = predict_data)\n",
    "    self.train_model()\n",
    "    self.block2topic()\n",
    "  \n",
    "  def block2topic(self):\n",
    "    df = pd.read_csv(\"/dbfs/Truc/introduction_blocks_topics.csv\")\n",
    "    self.block_topic = dict(list(zip(df[\"introduction_blockcode\"], df[\"topic\"])))\n",
    "    return self.block_topic\n",
    "  \n",
    "  # data normalization\n",
    "  def normalize_data(self, data):\n",
    "    columns = list(data.select_dtypes(\"number\").columns)\n",
    "    # check if this is training data or predicting data\n",
    "    if \"next_attempt\" in columns: \n",
    "      columns.remove(\"next_attempt\")\n",
    "      check_variables = [\"block_played\", \"question_played\", \"video_played\", \"avg_time_spent\", \"user_ft_avg_app_session_duration\", \"mean_time_watched\"]\n",
    "      print(\"before filter: \", len(data))\n",
    "      data[(data[\"block_played\"] <= 200) \n",
    "            & ((data[\"question_played\"] <= 1000) | (data[\"question_played\"].isna()))\n",
    "            & ((data[\"video_played\"] <= 200) | (data[\"video_played\"].isna()))\n",
    "            & (data[\"avg_time_spent\"] <= 5*3600) \n",
    "            & (data[\"user_ft_avg_app_session_duration\"] <= 10*3600) \n",
    "            & ((data[\"mean_time_watched\"] <= 3600) | (data[\"mean_time_watched\"].isna()))\n",
    "            ]\n",
    "      data = data.reset_index(drop=True)\n",
    "      print(\"after filter: \", len(data))\n",
    "    for c in columns:\n",
    "      if data[c].isna().sum() > len(data)/2:\n",
    "        data.drop(columns=[c], inplace=True)\n",
    "      else:\n",
    "        mean = data[c].mean()\n",
    "        data[c].fillna(mean, inplace=True)\n",
    "        std = data[c].std()\n",
    "        if std != 0:\n",
    "          data[c] = (data[c]-data[c].mean())/std\n",
    "        else:\n",
    "          data.drop(columns=[c], inplace=True)\n",
    "    return data.reset_index(drop=True)\n",
    "  \n",
    "  # split data for training\n",
    "  def train_test_split(self, data, validation = True):\n",
    "    n_samples = data.shape[0]\n",
    "    count = data.next_attempt.value_counts()\n",
    "    if count[0]/count[1] < 0.8 or count[1]/count[0] <0.8:\n",
    "      smote = SMOTE()\n",
    "      X = data.drop(columns=[\"next_attempt\"])\n",
    "      y = data[\"next_attempt\"]\n",
    "      X, y = smote.fit_resample(X, y)\n",
    "      data = X\n",
    "      data[\"next_attempt\"] = y\n",
    "    if validation:\n",
    "      sample = data.sample(n=n_samples)\n",
    "      msk = np.random.rand(len(sample)) < 0.8\n",
    "      non_test = sample[msk]\n",
    "      test = sample[~msk]\n",
    "      msk = np.random.rand(len(non_test)) < 0.7\n",
    "      train = non_test[msk]\n",
    "      validation = non_test[~msk]\n",
    "      return train, validation, test\n",
    "    else:\n",
    "      sample = data.sample(n=n_samples)\n",
    "      msk = np.random.rand(len(sample)) < 0.8\n",
    "      train = sample[msk]\n",
    "      test = sample[~msk]\n",
    "      return train, test\n",
    "  \n",
    "  #train Logistic Regression model and run feature selection\n",
    "  def train_model(self):\n",
    "    data = self.train_data.copy()\n",
    "    data = self.normalize_data(data).select_dtypes(\"number\")\n",
    "    train, test = self.train_test_split(data, validation = False)\n",
    "    y_train, y_test = train[\"next_attempt\"].values, test[\"next_attempt\"].values\n",
    "    self.model = LogisticRegression(fit_intercept=True, max_iter=200)\n",
    "    \n",
    "    all_features = train.drop(columns=[\"next_attempt\"]).columns\n",
    "    features = [([], 0)]\n",
    "    R_sq_fwd = []\n",
    "    \n",
    "    # forward stepwise feature selection\n",
    "    for k in range(1, len(all_features)):\n",
    "      best_k_minus_1 = features[-1][0]\n",
    "      new_features = list(set(all_features) - set(best_k_minus_1))\n",
    "      validation_R_sqs = []\n",
    "      for feature in new_features:\n",
    "        k_features = best_k_minus_1 + [feature]\n",
    "        X_train, X_test = train[k_features].values, test[k_features].values\n",
    "        if k==1:\n",
    "          X_train = X_train.reshape((len(X_train), 1))\n",
    "        self.model.fit(X_train, y_train)\n",
    "        validation_R_sqs.append(mean_squared_error(self.model.predict_proba(X_test)[:, 1], y_test))\n",
    "        \n",
    "      best_k = best_k_minus_1 + [new_features[np.argmin(validation_R_sqs)]]\n",
    "      R_sq_fwd.append(np.min(validation_R_sqs))\n",
    "      features.append((best_k, np.min(validation_R_sqs)))\n",
    "        \n",
    "    X_train, X_test = train[all_features].values, test[all_features].values\n",
    "    self.model.fit(X_train, y_train)\n",
    "    features.append((all_features, mean_squared_error(self.model.predict_proba(X_test)[:, 1], y_test)))\n",
    "    best_feature_set = sorted(features, key=lambda t: t[1])[1]\n",
    "    #train on the best feature set\n",
    "    self.model = LogisticRegression(fit_intercept=True).fit(data[best_feature_set[0]], data[\"next_attempt\"])\n",
    "    self.best_feature_set = best_feature_set[0]\n",
    "    return self.model\n",
    "  \n",
    "  # estimate probability score for every (user-block)\n",
    "  def predict(self):\n",
    "    scores = self.model.predict_proba(self.predict_data[self.best_feature_set])[:, 1]\n",
    "    #scores = self.model.predict(self.predict_data[self.best_feature_set])\n",
    "    self.block_scoring = self.predict_data[[\"UserId\", \"BlockCode\"]]\n",
    "    self.block_scoring[\"next_time_rate\"] = scores\n",
    "    self.block_scoring[\"topic\"] = self.block_scoring[\"BlockCode\"].apply(lambda x: self.block_topic[x])\n",
    "    self.block_scoring.to_csv(\"/dbfs/Truc/score.csv\")\n",
    "    return self.block_scoring\n",
    "  \n",
    "  def get_reccomend_topic(self, userid):\n",
    "    df = self.block_scoring[self.block_scoring[\"UserId\"]==userid]\n",
    "    score = zip(df[\"BlockCode\"], df[\"next_time_rate\"])\n",
    "    score = sort(score, key=lambda x: x[1], reverse=True)\n",
    "    return score\n",
    "  \n",
    "  def testing_method(self):\n",
    "    scores = self.model.predict(self.predict_data[self.best_feature_set])\n",
    "    block_scoring = self.predict_data[[\"UserId\", \"BlockCode\"]]\n",
    "    block_scoring[\"next_time_rate\"] = scores\n",
    "    return block_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "29b67210-cf09-4de4-a7b8-0355bbb6520d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Generator: Generate score table. This table is saved in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "23fd40aa-657c-4e6c-bf86-b8d166769a52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# generate scoring table for all users. This table is re-generated every two day (re-train model every two days)\n",
    "def generate_scoring_table(block_started, block_finished, video_played, question_played, user_features, block_features):\n",
    "  data_class = Data(user_ft = user_features, \n",
    "                  block_ft = block_features, \n",
    "                  block_start = block_started, \n",
    "                  block_finish = block_finished, \n",
    "                  question = question_played, \n",
    "                  video = video_played)\n",
    "  training_data = data_class.extract_all_features(latest = False)\n",
    "  predicting_data = data_class.extract_all_features(latest = True)\n",
    "  model = Predictor(train_data = training_data, predict_data = predicting_data)\n",
    "  ret_df = model.predict()\n",
    "  return ret_df;\n",
    "\n",
    "SCORING_TABLE = {\n",
    "    \"outputSpecs\": {\n",
    "        \"tableName\": \"scoring_table\",\n",
    "        \"indexColumns\": [\"UserId\", \"topic\"],\n",
    "        \"ifExists\": \"replace\"\n",
    "    },\n",
    "    \"inputSpecs\": [\n",
    "        {\n",
    "            \"alias\": \"block_started\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"norm_events_block_started\",\n",
    "        },\n",
    "        {\n",
    "            \"alias\": \"block_finished\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"norm_events_block_finished\",\n",
    "        },\n",
    "      {\n",
    "            \"alias\": \"video_played\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"norm_events_video_played\",\n",
    "        },\n",
    "      {\n",
    "            \"alias\": \"question_played\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"norm_events_question_played\",\n",
    "        },\n",
    "        {\n",
    "            \"alias\": \"user_features\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"analyzed_features_per_user\",\n",
    "        },\n",
    "        {\n",
    "            \"alias\": \"block_features\",\n",
    "            \"type\": \"delta_table_to_pandas\",\n",
    "            \"queryOrTable\": \"analyzed_features_per_block\",\n",
    "        },\n",
    "    ],\n",
    "    \"featureSpecs\": [\n",
    "        {\n",
    "            \"name\": \"generate_scoring_table\",\n",
    "            \"function\": generate_scoring_table,\n",
    "            \"functionInputs\": [\"block_started\", \"block_finished\", \"video_played\", \"question_played\", \"user_features\", \"block_features\"],\n",
    "            \"isTimeWindowFunction\": False\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "process = FeaturesTableGenerator(SCORING_TABLE)\n",
    "process.run()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Data",
   "notebookOrigID": 3452672976672618,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
