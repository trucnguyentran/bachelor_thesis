{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d68d929a-c259-4ae2-9e34-2a839ced5923",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Truc Tran -- i6213546\n",
    "### This file is used for analyzing results for 1st, 2nd and 3rd research question\n",
    "### Users are divided randomly into 3 groups:\n",
    "  Group A: The original Shadow Habtonomics Recommender\n",
    "  \n",
    "  Group B: The Multiply Hybrid Recommender\n",
    "  \n",
    "  Group C: The Convex Hxbrid Recommender\n",
    "  \n",
    "  significant level use: alpha = 0.1 and 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e6f3a665-a5e8-4c77-a3a3-4c6f0d39f0f1",
     "showTitle": true,
     "title": "import necessary library"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8462c319-6735-41c7-a985-f6ef292ed2e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Some defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d554ce3c-2ec9-4f49-a4ee-d82172079f87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mark1, mark2, mark3, mark4, mark5 = \"2022-04-05\", \"2022-04-26\", \"2022-05-17\", \"2022-05-24\", \"2022-06-15\"\n",
    "alpha = [0.1, 0.2]\n",
    "def take_group(_data:pd.DataFrame):\n",
    "  \"\"\"\n",
    "    method to track which group the user is in\n",
    "    this method is proposed by Back-end team\n",
    "    args: user dataframe\n",
    "    return: n dataframes for n groups\n",
    "  \"\"\"\n",
    "  data = _data.copy()\n",
    "  user_list = list(data[\"UserId\"])\n",
    "  userid_val = [sum([int(c) for c in userid if c.isdigit()]) for userid in user_list]\n",
    "  user_group = [1 if i%3==0 else 2 if i%3 == 1 else 3 for i in userid_val]\n",
    "  data[\"user_val\"] = userid_val\n",
    "  data[\"user_group\"] = user_group\n",
    "  \n",
    "  group1 = data[data[\"user_group\"] == 1].reset_index(drop=True)[[\"average_historic\", \"count_testing_period\"]]\n",
    "  group2 = data[data[\"user_group\"] == 2].reset_index(drop=True)[[\"average_historic\", \"count_testing_period\"]]\n",
    "  group3 = data[data[\"user_group\"] == 3].reset_index(drop=True)[[\"average_historic\", \"count_testing_period\"]]\n",
    "  return group1, group2, group3\n",
    "\n",
    "\n",
    "def count_block_session(_data:pd.DataFrame):\n",
    "  \"\"\"\n",
    "    method to track the total number of times to trigger blocks in testing period and average previous last 4 phases, each phase lasts 3 weeks\n",
    "    block_count_1: from 05-04 to 26-04\n",
    "    block_count_2: from 26-04 to 17-05\n",
    "    count_testing_period: from 24-05 to 14-06\n",
    "    block_count_average: average of 2 phases (1, 2): this will be used to compare with testing_period\n",
    "    user_group: testing group the user is in\n",
    "    return: dataframe contains userid and calculated block count in 3 phases\n",
    "  \"\"\"\n",
    "  data = _data[(mark1 <= _data[\"TimestampUtc\"]) & (_data[\"TimestampUtc\"] <= mark5)].reset_index(drop=True).copy()\n",
    "  p1 = data[(mark1 <= data[\"TimestampUtc\"]) & (data[\"TimestampUtc\"] < mark2)].groupby([\"UserId\"])[\"BlockCode\"].count().rename(\"block_count_1\").reset_index()\n",
    "  p2 = data[(mark2 <= data[\"TimestampUtc\"]) & (data[\"TimestampUtc\"] < mark3)].groupby([\"UserId\"])[\"BlockCode\"].count().rename(\"block_count_2\").reset_index()\n",
    "  p_test = data[(mark4 <= data[\"TimestampUtc\"]) & (data[\"TimestampUtc\"] < mark5)].groupby([\"UserId\"])[\"BlockCode\"].count().rename(\"count_testing_period\").reset_index()\n",
    "  \n",
    "  p = [p1, p2, p_test]\n",
    "  for i in p:\n",
    "    data = data.merge(i, on=\"UserId\", how=\"left\")\n",
    "  data = data[[\"UserId\", \"block_count_1\", \"block_count_2\", \"count_testing_period\"]]\n",
    "  data.drop_duplicates(inplace=True)\n",
    "  data[\"average_historic\"] = data[[\"block_count_1\", \"block_count_2\"]].mean(skipna=True, axis=1)\n",
    "  return data.reset_index(drop=True)\n",
    "\n",
    "def cohend(a, b, ind=True) -> float:\n",
    "  \"\"\"\n",
    "    method to calculate the cohen d effect size of two groups\n",
    "    args: 2 1-D numerical arrays a, b\n",
    "          boolean ind: a and b is independent or dependent\n",
    "    return: cohen'd size effect between a and b\n",
    "  \"\"\"\n",
    "  result = 0\n",
    "  if ind==True:\n",
    "    n1, n2 = len(a), len(b)\n",
    "    var1, var2 = np.var(a, ddof=1), np.var(b, ddof=1)\n",
    "    s = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    result = (np.mean(a) - np.mean(b))/s\n",
    "  else:\n",
    "    difference = np.array(a-b)\n",
    "    s = np.std(difference, ddof=1)\n",
    "    result = np.mean(difference)/s\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5032891e-64b1-492f-a0cd-a1270d2801aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RESEARCH QUESTION 1: improve the number of times finishing blocks (block_finished event) (historic vs testing)\n",
    "  1 tailed paired test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "89a2d0b2-83f9-49bf-8fb1-a9a39766a1a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#only take the blocks which were completed\n",
    "blockcomplete = spark.read.format(\"delta\").table(\"norm_events_block_finished\").toPandas()\n",
    "blockcomplete = blockcomplete[blockcomplete[\"CompletionState\"] == 1].reset_index(drop=True)\n",
    "data = count_block_session(blockcomplete)\n",
    "data_A, data_B, data_C = take_group(data)\n",
    "# take out data to do the paired t test. \n",
    "_data_A, _data_B, _data_C = data_A.dropna(), data_B.dropna(), data_C.dropna()\n",
    "\n",
    "#remove outlier \n",
    "_data_A = _data_A[(np.abs(stats.zscore(_data_A)) < 2).all(axis=1)]\n",
    "_data_B = _data_B[(np.abs(stats.zscore(_data_B)) < 2).all(axis=1)]\n",
    "_data_C = _data_C[(np.abs(stats.zscore(_data_C)) < 2).all(axis=1)]\n",
    "#plot data\n",
    "_data_A.boxplot()\n",
    "plt.ylabel(\"number of blocks\")\n",
    "plt.title('Group A')\n",
    "plt.show()\n",
    "_data_B.boxplot()\n",
    "plt.ylabel(\"number of blocks\")\n",
    "plt.title('Group B')\n",
    "plt.show()\n",
    "_data_C.boxplot()\n",
    "plt.ylabel(\"number of blocks\")\n",
    "plt.title('Group C')\n",
    "plt.show()\n",
    "# index 0 is is historic, index 1 testing period\n",
    "A = np.array([np.array(_data_A['average_historic']), np.array(_data_A['count_testing_period'])])\n",
    "B = np.array([np.array(_data_B['average_historic']), np.array(_data_B['count_testing_period'])])\n",
    "C = np.array([np.array(_data_C['average_historic']), np.array(_data_C['count_testing_period'])])\n",
    "\n",
    "#test normality. Small dataset so use wilk-shairo test here\n",
    "a_normal = stats.shapiro(A[1] - A[0])[1]\n",
    "b_normal = stats.shapiro(B[1] - B[0])[1]\n",
    "c_normal = stats.shapiro(C[1] - C[0])[1]\n",
    "#do the test\n",
    "a_pvalue, b_pvalue, c_pvalue = 0, 0, 0\n",
    "if a_normal <= alpha[0]:\n",
    "  print(\"Difference pairs of group A is not normally distributed\")\n",
    "  a_pvalue = stats.wilcoxon(A[0], A[1], alternative=\"greater\")[1]\n",
    "else:\n",
    "  print(\"Difference pairs of group A is normally distributed\")\n",
    "  a_pvalue = stats.ttest_rel(A[0], A[1], alternative=\"greater\")[1]\n",
    "  \n",
    "if b_normal <= alpha[0]:\n",
    "  print(\"Difference pairs of group B is not normally distributed\")\n",
    "  b_pvalue = stats.wilcoxon(B[0], B[1], alternative=\"greater\")[1]\n",
    "else:\n",
    "  print(\"Difference pairs of group B is normally distributed\")\n",
    "  b_pvalue = stats.ttest_rel(B[0], B[1], alternative=\"greater\")[1]\n",
    "  \n",
    "if c_normal <= alpha[0]:\n",
    "  print(\"Difference pairs of group C is not normally distributed\")\n",
    "  c_pvalue = stats.wilcoxon(C[0], C[1], alternative=\"greater\")[1]\n",
    "else:\n",
    "  print(\"Difference pairs of group C is normally distributed\")\n",
    "  c_pvalue = stats.ttest_rel(C[0], C[1], alternative=\"greater\")[1]\n",
    "  \n",
    "print(\"p value for the test of group A: \", a_pvalue)\n",
    "print(\"p value for the test of group B: \", b_pvalue)\n",
    "print(\"p value for the test of group C: \", c_pvalue) \n",
    "\n",
    "for i in alpha:\n",
    "  print(\"With alpha = \", i)\n",
    "  if b_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for group B, mean value of testing period is greater than that of average historic period\")\n",
    "  else:\n",
    "    print(\"   Cannot reject the null hypothesis for group B\")\n",
    "  \n",
    "  if c_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for group C, mean value of testing period is greater than that of average historic period\")\n",
    "  else:\n",
    "    print(\"   Cannot reject the null hypothesis for group C\")\n",
    "\n",
    "print(\"effect size between testing and recent period of group B: \", cohend(B[0], B[1], False))\n",
    "print(\"effect size between testing and recent period of group C: \", cohend(C[0], C[1], False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "07238ac7-a06a-4d62-9379-9b6e5e2fa4b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RESEARCH QUESTION 2: make better suggestions? (block_started and block_finished event) (A vs B and A vs C)\n",
    "### unpaired t test \n",
    "### First part: On block started event\n",
    "### Second part: On block finish event\n",
    "  1 tailed unpaired t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c038af4e-dcb4-4545-bfa9-c6ff9469bc8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Test on block started event\n",
    "\"\"\"\n",
    "blockstart = spark.read.format(\"delta\").table(\"norm_events_block_started\").toPandas()\n",
    "data = count_block_session(_data=blockstart)\n",
    "data_A, data_B, data_C = take_group(data)\n",
    "#filter nan value, take \"count_testing_period\" out\n",
    "_data_A, _data_B, _data_C = data_A[\"count_testing_period\"].dropna(), data_B[\"count_testing_period\"].dropna(), data_C[\"count_testing_period\"].dropna()\n",
    "\n",
    "#remove outlier\n",
    "_data_A = _data_A[np.abs(stats.zscore(_data_A)) <= 2]\n",
    "_data_B = _data_B[np.abs(stats.zscore(_data_B)) <= 2]\n",
    "_data_C = _data_C[np.abs(stats.zscore(_data_C)) <= 2]\n",
    "# take out data to do the unpaired t test\n",
    "A, B, C = np.array(_data_A), np.array(_data_B), np.array(_data_C)\n",
    "#plot data\n",
    "plt.boxplot(x = [A, B, C], labels = [\"group A\", \"group B\", \"group C\"])\n",
    "plt.ylabel(\"number of blocks\")\n",
    "plt.grid(True)\n",
    "plt.title(\"count testing period - block_started\")\n",
    "plt.show()\n",
    "\n",
    "#test normality\n",
    "anormal, bnormal, cnormal = stats.normaltest(A)[1], stats.normaltest(B)[1], stats.normaltest(C)[1]\n",
    "if anormal <= alpha[0]:\n",
    "  print(\"data from group A is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group A is normally distributed\")\n",
    "  \n",
    "if bnormal <= alpha[0]:\n",
    "  print(\"data from group B is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group B is normally distributed\")\n",
    "  \n",
    "if cnormal <= alpha[0]:\n",
    "  print(\"data from group C is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group C is normally distributed\")\n",
    "\n",
    "#do the test\n",
    "b_a_pvalue, c_a_pvalue = 0, 0\n",
    "if (anormal > alpha[0]) & (bnormal > alpha[0]):\n",
    "  b_a_pvalue = stats.ttest_ind(B, A, alternative=\"greater\")[1]\n",
    "else:\n",
    "  b_a_pvalue = stats.mannwhitneyu(B, A, alternative=\"greater\")[1]\n",
    "\n",
    "if (anormal > alpha[0]) & (cnormal > alpha[0]):\n",
    "  c_a_pvalue = stats.ttest_ind(C, A, alternative=\"greater\")[1]\n",
    "else:\n",
    "  c_a_pvalue = stats.mannwhitneyu(C, A, alternative=\"greater\")[1]\n",
    "\n",
    "print(\"p value for the test between group B and group A: \", b_a_pvalue)\n",
    "print(\"p value for the test between group C and group A: \", c_a_pvalue)\n",
    "\n",
    "for i in alpha:\n",
    "  print(\"With alpha = \", i)\n",
    "  if b_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and B, number of started blocks in group B is greater\")\n",
    "  else:\n",
    "    print(\"   Cannot reject the null hypothesis for the test between group A and B\")  \n",
    "\n",
    "  if c_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and C, number of started blocks in group C is greater\")\n",
    "  else:\n",
    "    print(\"   Cannot reject the null hypothesis for the test between group A and C\")\n",
    "\n",
    "print(\"effect size between group B and A: \", cohend(B, A, ind=True))\n",
    "print(\"effect size between group C and A: \", cohend(C, A, ind=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b9d2044c-7aa7-4122-86b5-8ecba49f56bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Test on block finished event\n",
    "\"\"\"\n",
    "blockcomplete = spark.read.format(\"delta\").table(\"norm_events_block_finished\").toPandas()\n",
    "blockcomplete = blockcomplete[blockcomplete[\"CompletionState\"] == 1].reset_index(drop=True)\n",
    "data = count_block_session(blockcomplete)\n",
    "data_A, data_B, data_C = take_group(data)\n",
    "#filter nan value, take \"count_testing_period\" out\n",
    "_data_A, _data_B, _data_C = data_A[\"count_testing_period\"].dropna(), data_B[\"count_testing_period\"].dropna(), data_C[\"count_testing_period\"].dropna()\n",
    "#remove outliers\n",
    "_data_A = _data_A[np.abs(stats.zscore(_data_A)) <= 2]\n",
    "_data_B = _data_B[np.abs(stats.zscore(_data_B)) <= 2]\n",
    "_data_C = _data_C[np.abs(stats.zscore(_data_C)) <= 2]\n",
    "# take out data to do the unpaired t test\n",
    "A, B, C = np.array(_data_A), np.array(_data_B), np.array(_data_C)\n",
    "#plot data\n",
    "plt.boxplot(x = [A, B, C], labels = [\"group A\", \"group B\", \"group C\"])\n",
    "plt.ylabel(\"number of blocks\")\n",
    "plt.grid(True)\n",
    "plt.title(\"count testing period - block_finished\")\n",
    "plt.show()\n",
    "#test normality\n",
    "anormal, bnormal, cnormal = stats.normaltest(A)[1], stats.normaltest(B)[1], stats.normaltest(C)[1]\n",
    "if anormal < alpha[0]:\n",
    "  print(\"data from group A is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group A is normally distributed\")\n",
    "  \n",
    "if bnormal <= alpha[0]:\n",
    "  print(\"data from group B is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group B is normally distributed\")\n",
    "  \n",
    "if cnormal <= alpha[0]:\n",
    "  print(\"data from group C is not normally distributed\")\n",
    "else:\n",
    "  print(\"data from group C is normally distributed\")\n",
    "\n",
    "#do the test\n",
    "b_a_pvalue, c_a_pvalue = 0, 0\n",
    "if (anormal > alpha[0]) & (bnormal > alpha[0]):\n",
    "  b_a_pvalue = stats.ttest_ind(B, A, alternative=\"greater\")[1]\n",
    "else:\n",
    "  b_a_pvalue = stats.mannwhitneyu(B, A, alternative=\"greater\")[1]\n",
    "\n",
    "if (anormal > alpha[0]) & (cnormal > alpha[0]):\n",
    "  c_a_pvalue = stats.ttest_ind(C, A, alternative=\"greater\")[1]\n",
    "else:\n",
    "  c_a_pvalue = stats.mannwhitneyu(C, A, alternative=\"greater\")[1]\n",
    "\n",
    "print(\"p value for the test between group B and group A: \", b_a_pvalue)\n",
    "print(\"p value for the test between group C and group A: \", c_a_pvalue)\n",
    "\n",
    "for i in alpha:\n",
    "  print(\"With alpha = \", i)\n",
    "  if b_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and B, number of started blocks in group B is greater\")\n",
    "  else:\n",
    "    print(\"   cannot reject the null hypothesis for the test between group A and B\")  \n",
    "  if c_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and C, number of started blocks in group C is greater\")\n",
    "  else:\n",
    "    print(\"   cannot reject the null hypothesis for the test between group A and C\")\n",
    "\n",
    "print(\"effect size between group B and A: \", cohend(B, A, ind=True))\n",
    "print(\"effect size between group C and A: \", cohend(C, A, ind=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e480142b-ccf7-4edc-a3bd-dfe577cf5fa8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## RESEARCH QUESTION 3: satisfaction level (from survey)\n",
    "### first part: one sample t test\n",
    "### second part: unpaired t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a0f9228d-5ea2-4cdb-9ce5-addb7a961d74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#read csv file\n",
    "survey = pd.read_csv(\"survey_result.csv\")\n",
    "satisfied_level = np.array(survey[\"satisfied\"])\n",
    "\"\"\"\n",
    "  first part: Measure satisfaction level of all users\n",
    "\"\"\"\n",
    "print(\"First part:\")\n",
    "pnormal = stats.normaltest(satisfied_level)[1]\n",
    "\n",
    "p_value_55, p_value_60 = 0, 0\n",
    "if pnormal > alpha[0]:\n",
    "  print(\"data is approximately normally distributed\")\n",
    "  p_value_55 = stats.ttest_1samp(satisfied_level, 5.5, alternative=\"greater\")[1]\n",
    "  p_value_60 = stats.ttest_1samp(satisfied_level, 6, alternative=\"greater\")[1]\n",
    "else:\n",
    "  print(\"data is not normally distributed\")\n",
    "  p_value_55 = stats.wilcoxon(satisfied_level-5.5, alternative=\"greater\")[1]\n",
    "  p_value_60 = stats.wilcoxon(satisfied_level-6.0, alternative=\"greater\")[1]\n",
    "\n",
    "print(\"5.5: \", p_value_55)\n",
    "print(\"6: \", p_value_60)\n",
    "for i in alpha:\n",
    "  print(\"With alpha = \", i)\n",
    "  if p_value_55 <= i:\n",
    "    print(\"   At 5.5: Reject the null hypothesis. In average users are satisfied with the recommendations\")\n",
    "  else:\n",
    "    print(\"   At 5.5: Cannot reject the null hypothesis\")  \n",
    "  if p_value_60 <= i:\n",
    "    print(\"   At 6.0: Reject the null hypothesis. In average users are satisfied with the recommendations\")\n",
    "  else:\n",
    "    print(\"   At 6.0: Cannot reject the null hypothesis\")\n",
    "\n",
    "\"\"\"\n",
    "  second part: Perform comparison of A vs B, and A vs C (We have that A, B, C is approximately normally distributed)\n",
    "\"\"\"\n",
    "print(\"Second part:\")\n",
    "A = np.array(survey[survey[\"group\"] == 0][\"satisfied\"])\n",
    "B = np.array(survey[survey[\"group\"] == 1][\"satisfied\"])\n",
    "C = np.array(survey[survey[\"group\"] == 2][\"satisfied\"])\n",
    "plt.boxplot(x=[satisfied_level, A, B, C], labels=[\"all users\", \"group A\", \"group B\", \"group C\"])\n",
    "plt.ylabel(\"level\")\n",
    "plt.title(\"Satisfaction level of users in the testing period\")\n",
    "plt.show()\n",
    "\n",
    "b_a_pvalue = stats.ttest_ind(B, A, alternative=\"greater\")[1]\n",
    "c_a_pvalue = stats.ttest_ind(C, A, alternative=\"greater\")[1]\n",
    "print(\"pvalue B vs A: \", b_a_pvalue)\n",
    "print(\"pvalue C vs A: \", c_a_pvalue)\n",
    "\n",
    "for i in alpha:\n",
    "  print(\"With alpha = \", i)\n",
    "  if b_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and B, users in group B feel more satsfied\")\n",
    "  else:\n",
    "    print(\"   cannot reject the null hypothesis for the test between group A and B\")  \n",
    "  if c_a_pvalue <= i:\n",
    "    print(\"   Reject the null hypothesis for the test between group A and C, users in group C feel more satsfied\")\n",
    "  else:\n",
    "    print(\"   cannot reject the null hypothesis for the test between group A and C\")\n",
    "    \n",
    "print(\"effect size between group B and A: \", cohend(B, A, ind=True))\n",
    "print(\"effect size between group C and A: \", cohend(C, A, ind=True))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "check_data",
   "notebookOrigID": 413799945950479,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
